<h1 align="center">
    <img src="./lib/assets/icons/icon.png" width="25" height="25"/>
    Simple Kana Recognizer
</h1>

<p align="center">
Simple Kana Recognizer is an app built in Flutter that allows you to recognize the kana (hiragana and katakana) drawn in the app.
</p>

<p align="center">
 <a href="#about-the-project">About the project</a> •
 <a href="#technologies">Technologies</a> • 
 <a href="#license">License</a>
</p>

# About the project

The project consists of recognizing the user-drawn kanas on an android (iOS was not used due to the lack of equipment to test).

<p align="center">
<img alt="1" title="1" src="./git_images/1.png" width="200"  />
<img alt="2" title="2" src="./git_images/2.png" width="200"  />
<img alt="3" title="3" src="./git_images/3.png" width="200" />
</p>

To build the application, Flutter was used with the MVC architecture only to separate it into layers.

* The view layer contains the page and state management as well as the part that recognizes the points drawn on the screen.

* The controller layer contains the logic of each page and stores the data as the points of each drawn trace. It also recover data from the model layer as well as redirects the data to be processed outside the controller.

* The model layer contains the data store. As there is little data, no database was used, as there is no need to add complexity. It also contains services that simulate external packages in which one is used to reduce points using the Ramer–Douglas–Peucker algorithm and another algorithm to recognize the points of strokes in kana.

The kana points for comparison were taken from the SVG images generated by [Ulrich Apel - KanjiVG](https://kanjivg.tagaini.net/). To generate the points, I created an algorithm in python where it extracts, separates only the kanas (hiragana to katakana) and takes the points from the SVG images. However, as the points were insufficient for the algorithm, I needed to increase the amount of points in each image using Inkscape.

<p align="center">
<img alt="Before" title="Before" src="./git_images/before.png" width="200" height="200" />
<img alt="After" title="After" src="./git_images/after.png" width="240" height="200" />
</p>

The Ramer–Douglas–Peucker algorithm was based on the project of [Snegovikufa](https://gist.github.com/Snegovikufa/6490663).

To draw and recover the stroke points, it was based on the project of [jayndu](https://jaycoding.tech/tutorials/guides/efficient-sketching-app-using-flutter-icstum).

# Technologies

<p><img alt="Dart" src="https://img.shields.io/badge/Dart-2.13.4-03589b?style=for-the-badge&logo=dart"></p>
<p><img alt="Flutter" src="https://img.shields.io/badge/Flutter-2.2.3-53c5f7?style=for-the-badge&logo=flutter"></p>
<p><img alt="Python" src="https://img.shields.io/badge/Python-3.8.10-fadf5e?style=for-the-badge&logo=python"></p>
<p><img alt="Python" src="https://img.shields.io/badge/svgpathtools-1.4.1-fadf5e?style=for-the-badge"></p>

# License

The license is in accordance with MIT, however, while not mandatory, I would like you to cite that the code was based on this project.
